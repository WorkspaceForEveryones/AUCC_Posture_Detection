{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('./postures/ex5-1.jpg')\n",
    "\n",
    "# Convert the image to RGB format\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process the image with MediaPipe Pose\n",
    "results = pose.process(image)\n",
    "\n",
    "# Draw landmarks on the image\n",
    "annotated_image = image.copy()\n",
    "mp_drawing.draw_landmarks(\n",
    "    annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Get the location of two specific landmarks (e.g. left shoulder and right shoulder)\n",
    "left_hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP]\n",
    "right_hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP]\n",
    "left_knee = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE]\n",
    "right_knee = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE]\n",
    "left_ankle = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ANKLE]\n",
    "right_ankle = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE]\n",
    "\n",
    "\n",
    "# Draw a straight line connecting the two landmarks\n",
    "cv2.line(annotated_image, (int(left_hip.x * image.shape[1]), int(left_hip.y * image.shape[0])),\n",
    "         (int(left_knee.x * image.shape[1]), int(left_knee.y * image.shape[0])), (255, 0, 0), 5)\n",
    "\n",
    "# Display the annotated image\n",
    "scale_percent = 40  # percent of original size\n",
    "resized_image = cv2.resize(annotated_image, (0, 0), fx=scale_percent /\n",
    "                           100, fy=scale_percent/100, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Display the annotated image\n",
    "if scale_percent != 100:\n",
    "    cv2.imshow('MediaPipe Pose', resized_image)\n",
    "else:\n",
    "    cv2.imshow('MediaPipe Pose', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('./postures/ex6-1.jpg')\n",
    "\n",
    "# Convert the image to RGB format\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process the image with MediaPipe Pose\n",
    "results = pose.process(image)\n",
    "\n",
    "# Draw landmarks on the image\n",
    "annotated_image = image.copy()\n",
    "mp_drawing.draw_landmarks(\n",
    "    annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Define the list of landmark pairs to connect with lines\n",
    "landmark_pairs = [(mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "                  (mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "                   mp_pose.PoseLandmark.RIGHT_SHOULDER)]\n",
    "\n",
    "# Draw lines connecting the landmark pairs\n",
    "for pair in landmark_pairs:\n",
    "    start = results.pose_landmarks.landmark[pair[0]]\n",
    "    end = results.pose_landmarks.landmark[pair[1]]\n",
    "    cv2.line(annotated_image, (int(start.x * image.shape[1]), int(start.y * image.shape[0])),\n",
    "             (int(end.x * image.shape[1]), int(end.y * image.shape[0])), (255, 0, 0), 5)\n",
    "\n",
    "# Resize the annotated image for display\n",
    "scale_percent = 40  # percent of original size\n",
    "resized_image = cv2.resize(annotated_image, (0, 0), fx=scale_percent /\n",
    "                           100, fy=scale_percent/100, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Display the annotated image\n",
    "if scale_percent != 100:\n",
    "    cv2.imshow('MediaPipe Pose', resized_image)\n",
    "else:\n",
    "    cv2.imshow('MediaPipe Pose', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detected intersection - no intersection, draw lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_intersection(line1, line2):\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    d = (x1-x2)*(y3-y4) - (y1-y2)*(x3-x4)\n",
    "    if d != 0:\n",
    "        # Calculate the point of intersection\n",
    "        px = ((x1*y2-y1*x2)*(x3-x4) - (x1-x2)*(x3*y4-y3*x4)) / d\n",
    "        py = ((x1*y2-y1*x2)*(y3-y4) - (y1-y2)*(x3*y4-y3*x4)) / d\n",
    "        # Check if the point of intersection is within the line segments\n",
    "        if (min(x1, x2) <= px <= max(x1, x2) and min(y1, y2) <= py <= max(y1, y2)\n",
    "                and min(x3, x4) <= px <= max(x3, x4) and min(y3, y4) <= py <= max(y3, y4)):\n",
    "            return (px, py)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    " \n",
    "def cal_angle(start1 ,  start2 , end1 , end2):\n",
    "    # Calculate the sine of the angle between the lines\n",
    "    sin_angle = ((end1.y - start1.y) * (end2.x - start2.x)) - \\\n",
    "        ((end2.y - start2.y) * (end1.x - start1.x))\n",
    "        \n",
    "    sin_angle /= math.sqrt(((end1.y - start1.y)**2 + (end1.x - start1.x)**2) * \\\n",
    "                           ((end2.y - start2.y)**2 + (end2.x - start2.x)**2))\n",
    "\n",
    "    # Calculate the angle in degrees from the sine\n",
    "    angle = math.asin(sin_angle) * 180 / math.pi\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช็คขาไหว้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.644729396731286\n",
      "ขาไขว้กัน\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Load the input image\n",
    "# image = cv2.imread('./postures/ex02.jpg')\n",
    "image = cv2.imread('./postures/ex02.jpg')\n",
    "\n",
    "# Convert the image to RGB format\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process the image with MediaPipe Pose\n",
    "results = pose.process(image)\n",
    "\n",
    "# Draw landmarks on the image\n",
    "annotated_image = image.copy()\n",
    "mp_drawing.draw_landmarks(\n",
    "annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Define the landmark pairs\n",
    "hip_knee_pairs = [(mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE),\n",
    "                  (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE)]\n",
    "knee_ankle_pairs = [(mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "                  (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE)]\n",
    "\n",
    "left_angle = []\n",
    "# Draw lines connecting the landmark pairs and check for intersections\n",
    "for pair in hip_knee_pairs:\n",
    "    start1 = results.pose_landmarks.landmark[pair[0]]\n",
    "    end1 = results.pose_landmarks.landmark[pair[1]]\n",
    "    cv2.line(annotated_image, (int(start1.x * image.shape[1]), int(start1.y * image.shape[0])),\n",
    "             (int(end1.x * image.shape[1]), int(end1.y * image.shape[0])), (255, 0, 0), 2)\n",
    "    left_angle.append((start1,end1))\n",
    "    \n",
    "angle1 = cal_angle(left_angle[0][0],left_angle[1][0],left_angle[0][1],left_angle[1][1])\n",
    "\n",
    "# intersection_hip_knee = set()\n",
    "\n",
    "right_angle = []\n",
    "# Draw lines connecting the landmark pairs and check for intersections\n",
    "for pair in knee_ankle_pairs:\n",
    "    start2 = results.pose_landmarks.landmark[pair[0]]\n",
    "    end2 = results.pose_landmarks.landmark[pair[1]]\n",
    "    cv2.line(annotated_image, (int(start2.x * image.shape[1]), int(start2.y * image.shape[0])),\n",
    "             (int(end2.x * image.shape[1]), int(end2.y * image.shape[0])), (255, 0, 0), 2)\n",
    "    right_angle.append((start2,end2))\n",
    "    \n",
    "angle2 = cal_angle(right_angle[0][0],right_angle[1][0],right_angle[0][1],right_angle[1][1])\n",
    "diff_angle_knee = abs(angle1-angle2)\n",
    "print(diff_angle_knee)\n",
    "if diff_angle_knee <= 50 and diff_angle_knee >= 10:\n",
    "    print(\"ขาไขว้กัน\")\n",
    "else:\n",
    "    print(\"กรูณาถอยเท้าข้างที่ถนัดไปด้านหลังค่ะ\")\n",
    "\n",
    "# intersection_knee_ankle = set()\n",
    "\n",
    "# check_intersection_hip_knee = 0;\n",
    "# check_intersection_knee_ankle = 0\n",
    "\n",
    "# # Check for intersections between lines connecting LEFT_HIP to LEFT_KNEE and RIGHT_HIP to RIGHT_KNEE\n",
    "# for i in range(len(hip_knee_pairs)):\n",
    "#     start1 = results.pose_landmarks.landmark[hip_knee_pairs[i][0]]\n",
    "#     end1 = results.pose_landmarks.landmark[hip_knee_pairs[i][1]]\n",
    "#     for j in range(i+1, len(hip_knee_pairs)):\n",
    "#         start2 = results.pose_landmarks.landmark[hip_knee_pairs[j][0]]\n",
    "#         end2 = results.pose_landmarks.landmark[hip_knee_pairs[j][1]]\n",
    "#         if check_intersection((start1.x * image.shape[1], start1.y * image.shape[0], end1.x * image.shape[1], end1.y * image.shape[0]), (start2.x * image.shape[1], start2.y * image.shape[0], end2.x * image.shape[1], end2.y * image.shape[0])):\n",
    "#             intersection_hip_knee.add((start1.x * image.shape[1], start1.y * image.shape[0], end1.x * image.shape[1], end1.y * image.shape[0],\n",
    "#                               start2.x * image.shape[1], start2.y * image.shape[0], end2.x * image.shape[1], end2.y * image.shape[0]))\n",
    "#             cv2.putText(annotated_image, \"Intersection\", (50, 50),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#             print(\"ต้นขาไขว้กัน\")\n",
    "\n",
    "# if len(intersection_hip_knee) == 0:\n",
    "#     cv2.putText(annotated_image, \"No Intersection\", (50, 50),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#     print(\"ต้นขาไม่ไขว้กัน\")\n",
    "#     check_intersection_hip_knee = 1\n",
    "\n",
    "\n",
    "# # Check for intersections between lines connecting LEFT_HIP to LEFT_KNEE and RIGHT_HIP to RIGHT_KNEE\n",
    "# for i in range(len(knee_ankle_pairs)):\n",
    "#     start1 = results.pose_landmarks.landmark[knee_ankle_pairs[i][0]]\n",
    "#     end1 = results.pose_landmarks.landmark[knee_ankle_pairs[i][1]]\n",
    "#     for j in range(i+1, len(knee_ankle_pairs)):\n",
    "#         start2 = results.pose_landmarks.landmark[knee_ankle_pairs[j][0]]\n",
    "#         end2 = results.pose_landmarks.landmark[knee_ankle_pairs[j][1]]\n",
    "#         if check_intersection((start1.x * image.shape[1], start1.y * image.shape[0], end1.x * image.shape[1], end1.y * image.shape[0]), (start2.x * image.shape[1], start2.y * image.shape[0], end2.x * image.shape[1], end2.y * image.shape[0])):\n",
    "#             intersection_knee_ankle.add((start1.x * image.shape[1], start1.y * image.shape[0], end1.x * image.shape[1], end1.y * image.shape[0],\n",
    "#                               start2.x * image.shape[1], start2.y * image.shape[0], end2.x * image.shape[1], end2.y * image.shape[0]))\n",
    "#             cv2.putText(annotated_image, \"\", (50, 50),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#             print(\"ขาไขว้กัน\")\n",
    "\n",
    "# if len(intersection_knee_ankle) == 0:\n",
    "#     cv2.putText(annotated_image, \"\", (50, 50),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#     print(\"ขาไม่ไขว้กัน\")\n",
    "#     check_intersection_knee_ankle += 1\n",
    "\n",
    "# # Checking if there is no intercetion in couplelines\n",
    "# if len(intersection_knee_ankle or intersection_hip_knee) == 0:\n",
    "#     print(\"กรูณาถอยเท้าข้างที่ถนัดไปด้านหลังค่ะ\")\n",
    "\n",
    "\n",
    "# Resize the annotated image for display\n",
    "scale_percent = 40  # percent of original size\n",
    "resized_image = cv2.resize(annotated_image, (0, 0), fx=scale_percent /\n",
    "                           100, fy=scale_percent/100, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Display the annotated image\n",
    "if scale_percent != 100:\n",
    "    cv2.imshow('Detected img', resized_image)\n",
    "else:\n",
    "    cv2.imshow('Detected img', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช็คโน้มตัวไปข้างหน้า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between lines 1 and 2: 64.66 degrees\n",
      "โน้มตัวไปด้านหน้าแล้ว\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('./postures/ex03.jpg')\n",
    "\n",
    "# Convert the image to RGB format\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process the image with MediaPipe Pose\n",
    "results = pose.process(image)\n",
    "\n",
    "# Draw landmarks on the image\n",
    "annotated_image = image.copy()\n",
    "mp_drawing.draw_landmarks(\n",
    "    annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Define the list of landmark pairs to connect with lines\n",
    "landmark_pairs = [(mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "                  (mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE)]\n",
    "\n",
    "# Draw lines connecting the landmark pairs\n",
    "for i in range(len(landmark_pairs)):\n",
    "    start1 = results.pose_landmarks.landmark[landmark_pairs[i][0]] #(x1, y1)\n",
    "    end1 = results.pose_landmarks.landmark[landmark_pairs[i][1]] #(x2, y2)\n",
    "    cv2.line(annotated_image, (int(start1.x * image.shape[1]), int(start1.y * image.shape[0])),\n",
    "             (int(end1.x * image.shape[1]), int(end1.y * image.shape[0])), (255, 0, 0), 5)\n",
    "\n",
    "    if i < len(landmark_pairs) - 1:\n",
    "        start2 = results.pose_landmarks.landmark[landmark_pairs[i+1][0]] #(x3,y3)\n",
    "        end2 = results.pose_landmarks.landmark[landmark_pairs[i+1][1]] #(x4,y4)\n",
    "        \n",
    "        # Check if the angle is less than 75 degrees and print \"Yes\" or \"No\"\n",
    "        angle = cal_angle(start1,start2,end1,end2)\n",
    "        print(f\"Angle between lines {i+1} and {i+2}: {angle:.2f} degrees\")\n",
    "        if angle <= 80 and angle >= 45:\n",
    "            print(\"โน้มตัวไปด้านหน้าแล้ว\")\n",
    "        else:\n",
    "            print(\"กรุณาโน้มตัวไปด้านหน้าค่ะ\")\n",
    "\n",
    "    \n",
    "# Resize the annotated image for display\n",
    "scale_percent = 40  # percent of original size\n",
    "resized_image = cv2.resize(annotated_image, (0, 0), fx=scale_percent /\n",
    "                           100, fy=scale_percent/100, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Display the annotated image\n",
    "if scale_percent != 100:\n",
    "    cv2.imshow('MediaPipe Pose', resized_image)\n",
    "else:\n",
    "    cv2.imshow('MediaPipe Pose', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช็คใช้แขนค้ำยัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between lines 1 and 2: 42.00 degrees\n",
      "ใช้แขนค้ำยันแล้ว\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('./postures/ex04.jpg')\n",
    "\n",
    "# Convert the image to RGB format\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process the image with MediaPipe Pose\n",
    "results = pose.process(image)\n",
    "\n",
    "# Draw landmarks on the image\n",
    "annotated_image = image.copy()\n",
    "mp_drawing.draw_landmarks(\n",
    "    annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Define the list of landmark pairs to connect with lines\n",
    "landmark_pairs = [(mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "                   mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "                  (mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "                   mp_pose.PoseLandmark.RIGHT_WRIST)]\n",
    "\n",
    "# Draw lines connecting the landmark pairs\n",
    "for i in range(len(landmark_pairs)):\n",
    "    start1 = results.pose_landmarks.landmark[landmark_pairs[i][0]]\n",
    "    end1 = results.pose_landmarks.landmark[landmark_pairs[i][1]]\n",
    "    cv2.line(annotated_image, (int(start1.x * image.shape[1]), int(start1.y * image.shape[0])),\n",
    "             (int(end1.x * image.shape[1]), int(end1.y * image.shape[0])), (255, 0, 0), 5)\n",
    "\n",
    "    if i < len(landmark_pairs) - 1:\n",
    "        start2 = results.pose_landmarks.landmark[landmark_pairs[i+1][0]]\n",
    "        end2 = results.pose_landmarks.landmark[landmark_pairs[i+1][1]]\n",
    "\n",
    "        # Check if the angle is less than 40 degrees and  more than 10 degrees print \"Yes\" or \"No\"\n",
    "        angle = cal_angle(start1 , start2 ,end1 ,end2)\n",
    "        print(f\"Angle between lines {i+1} and {i+2}: {angle:.2f} degrees\")\n",
    "        if angle <= 45 and angle >= 10:\n",
    "            print(\"ใช้แขนค้ำยันแล้ว\")\n",
    "        else:\n",
    "            print(\"กรุณาใช้แขนค้ำยันก่อนลุกยืนค่ะ\")\n",
    "\n",
    "\n",
    "# Resize the annotated image for display\n",
    "scale_percent = 40  # percent of original size\n",
    "resized_image = cv2.resize(annotated_image, (0, 0), fx=scale_percent /\n",
    "                           100, fy=scale_percent/100, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Display the annotated image\n",
    "if scale_percent != 100:\n",
    "    cv2.imshow('MediaPipe Pose', resized_image)\n",
    "else:\n",
    "    cv2.imshow('MediaPipe Pose', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle between lines 1 and 2: -21.06 degrees\n",
      "ยืนตรงแล้ว\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Pose model\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('./postures/ex05.jpg')\n",
    "\n",
    "# Convert the image to RGB format\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Process the image with MediaPipe Pose\n",
    "results = pose.process(image)\n",
    "\n",
    "# Draw landmarks on the image\n",
    "annotated_image = image.copy()\n",
    "mp_drawing.draw_landmarks(\n",
    "    annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# Define the list of landmark pairs to connect with lines\n",
    "landmark_pairs = [(mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "                   mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "                  (mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "                   mp_pose.PoseLandmark.RIGHT_ANKLE)]\n",
    "\n",
    "\n",
    "# Draw lines connecting the landmark pairs\n",
    "for i in range(len(landmark_pairs)):\n",
    "    start1 = results.pose_landmarks.landmark[landmark_pairs[i][0]]\n",
    "    end1 = results.pose_landmarks.landmark[landmark_pairs[i][1]]\n",
    "    cv2.line(annotated_image, (int(start1.x * image.shape[1]), int(start1.y * image.shape[0])),\n",
    "             (int(end1.x * image.shape[1]), int(end1.y * image.shape[0])), (255, 0, 0), 5)\n",
    "\n",
    "    if i < len(landmark_pairs) - 1:\n",
    "        start2 = results.pose_landmarks.landmark[landmark_pairs[i+1][0]]\n",
    "        end2 = results.pose_landmarks.landmark[landmark_pairs[i+1][1]]\n",
    "\n",
    "        angle = cal_angle(start1,start2,end1,end2)\n",
    "        print(f\"Angle between lines {i+1} and {i+2}: {angle:.2f} degrees\")\n",
    "\n",
    "# Check if the different of angle is less than -- degrees and print \"Yes\" or \"No\"\n",
    "if angle >= -25 and angle <= 15:\n",
    "    print(\"ยืนตรงแล้ว\")\n",
    "else:\n",
    "    print(\"กรุณาลุกขึ้นช้าๆ\")\n",
    "\n",
    "\n",
    "# Resize the annotated image for display\n",
    "scale_percent = 40  # percent of original size\n",
    "resized_image = cv2.resize(annotated_image, (0, 0), fx=scale_percent /\n",
    "                           100, fy=scale_percent/100, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Display the annotated image\n",
    "if scale_percent != 100:\n",
    "    cv2.imshow('MediaPipe Pose', resized_image)\n",
    "else:\n",
    "    cv2.imshow('MediaPipe Pose', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
